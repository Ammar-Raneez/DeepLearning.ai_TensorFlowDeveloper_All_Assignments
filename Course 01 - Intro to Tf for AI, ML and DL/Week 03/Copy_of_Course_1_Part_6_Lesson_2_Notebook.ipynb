{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Course 1 - Part 6 - Lesson 2 - Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "BZSlp3DAjdYf",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R6gHiH-I7uFa"
      },
      "source": [
        "#Improving Computer Vision Accuracy using Convolutions\n",
        "\n",
        "In the previous lessons you saw how to do fashion recognition using a Deep Neural Network (DNN) containing three layers -- the input layer (in the shape of the data), the output layer (in the shape of the desired output) and a hidden layer. You experimented with the impact of different sizes of hidden layer, number of training epochs etc on the final accuracy.\n",
        "\n",
        "For convenience, here's the entire code again. Run it and take a note of the test accuracy that is printed out at the end. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xcsRtq9OLorS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "8d351f67-6c7b-47e0-f6bf-4f1426422f93"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images / 255.0\n",
        "test_images=test_images / 255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4969 - accuracy: 0.8249\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3722 - accuracy: 0.8664\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3358 - accuracy: 0.8772\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3097 - accuracy: 0.8856\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2931 - accuracy: 0.8923\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3522 - accuracy: 0.8754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zldEXSsF8Noz"
      },
      "source": [
        "Your accuracy is probably about 89% on training and 87% on validation...not bad...But how do you make that even better? One way is to use something called Convolutions. I'm not going to details on Convolutions here, but the ultimate concept is that they narrow down the content of the image to focus on specific, distinct, details. \n",
        "\n",
        "If you've ever done image processing using a filter (like this: https://en.wikipedia.org/wiki/Kernel_(image_processing)) then convolutions will look very familiar.\n",
        "\n",
        "In short, you take an array (usually 3x3 or 5x5) and pass it over the image. By changing the underlying pixels based on the formula within that matrix, you can do things like edge detection. So, for example, if you look at the above link, you'll see a 3x3 that is defined for edge detection where the middle cell is 8, and all of its neighbors are -1. In this case, for each pixel, you would multiply its value by 8, then subtract the value of each neighbor. Do this for every pixel, and you'll end up with a new image that has the edges enhanced.\n",
        "\n",
        "This is perfect for computer vision, because often it's features that can get highlighted like this that distinguish one item for another, and the amount of information needed is then much less...because you'll just train on the highlighted features.\n",
        "\n",
        "That's the concept of Convolutional Neural Networks. Add some layers to do convolution before you have the dense layers, and then the information going to the dense layers is more focussed, and possibly more accurate.\n",
        "\n",
        "Run the below code -- this is the same neural network as earlier, but this time with Convolutional layers added first. It will take longer, but look at the impact on the accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C0tFgT1MMKi6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9acd8678-e295-4d76-89cf-cec789835ecf"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=20)\n",
        "test_loss = model.evaluate(test_images, test_labels)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4428 - accuracy: 0.8398\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2968 - accuracy: 0.8916\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2496 - accuracy: 0.9084\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2183 - accuracy: 0.9191\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1909 - accuracy: 0.9279\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1688 - accuracy: 0.9371\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1495 - accuracy: 0.9437\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1294 - accuracy: 0.9517\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1156 - accuracy: 0.9571\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1037 - accuracy: 0.9612\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0903 - accuracy: 0.9655\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0803 - accuracy: 0.9694\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0710 - accuracy: 0.9730\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0644 - accuracy: 0.9755\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0590 - accuracy: 0.9778\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0519 - accuracy: 0.9809\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0504 - accuracy: 0.9809\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0441 - accuracy: 0.9839\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0424 - accuracy: 0.9843\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0368 - accuracy: 0.9861\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4854 - accuracy: 0.9115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uRLfZ0jt-fQI"
      },
      "source": [
        "It's likely gone up to about 93% on the training data and 91% on the validation data. \n",
        "\n",
        "That's significant, and a step in the right direction!\n",
        "\n",
        "Try running it for more epochs -- say about 20, and explore the results! But while the results might seem really good, the validation results may actually go down, due to something called 'overfitting' which will be discussed later. \n",
        "\n",
        "(In a nutshell, 'overfitting' occurs when the network learns the data from the training set really well, but it's too specialised to only that data, and as a result is less effective at seeing *other* data. For example, if all your life you only saw red shoes, then when you see a red shoe you would be very good at identifying it, but blue suade shoes might confuse you...and you know you should never mess with my blue suede shoes.)\n",
        "\n",
        "Then, look at the code again, and see, step by step how the Convolutions were built:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RaLX5cgI_JDb"
      },
      "source": [
        "Step 1 is to gather the data. You'll notice that there's a bit of a change here in that the training data needed to be reshaped. That's because the first convolution expects a single tensor containing everything, so instead of 60,000 28x28x1 items in a list, we have a single 4D list that is 60,000x28x28x1, and the same for the test images. If you don't do this, you'll get an error when training as the Convolutions do not recognize the shape. \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SS_W_INc_kJQ"
      },
      "source": [
        "Next is to define your model. Now instead of the input layer at the top, you're going to add a Convolution. The parameters are:\n",
        "\n",
        "1. The number of convolutions you want to generate. Purely arbitrary, but good to start with something in the order of 32\n",
        "2. The size of the Convolution, in this case a 3x3 grid\n",
        "3. The activation function to use -- in this case we'll use relu, which you might recall is the equivalent of returning x when x>0, else returning 0\n",
        "4. In the first layer, the shape of the input data.\n",
        "\n",
        "You'll follow the Convolution with a MaxPooling layer which is then designed to compress the image, while maintaining the content of the features that were highlighted by the convlution. By specifying (2,2) for the MaxPooling, the effect is to quarter the size of the image. Without going into too much detail here, the idea is that it creates a 2x2 array of pixels, and picks the biggest one, thus turning 4 pixels into 1. It repeats this across the image, and in so doing halves the number of horizontal, and halves the number of vertical pixels, effectively reducing the image by 25%.\n",
        "\n",
        "You can call model.summary() to see the size and shape of the network, and you'll notice that after every MaxPooling layer, the image size is reduced in this way. \n",
        "\n",
        "\n",
        "```\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RMorM6daADjA"
      },
      "source": [
        "Add another convolution\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b1-x-kZF4_tC"
      },
      "source": [
        "Now flatten the output. After this you'll just have the same DNN structure as the non convolutional version\n",
        "\n",
        "```\n",
        "  tf.keras.layers.Flatten(),\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qPtqR23uASjX"
      },
      "source": [
        "The same 128 dense layers, and 10 output layers as in the pre-convolution example:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C0GSsjUhAaSj"
      },
      "source": [
        "Now compile the model, call the fit method to do the training, and evaluate the loss and accuracy from the test set.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IXx_LX3SAlFs"
      },
      "source": [
        "# Visualizing the Convolutions and Pooling\n",
        "\n",
        "This code will show us the convolutions graphically. The print (test_labels[;100]) shows us the first 100 labels in the test set, and you can see that the ones at index 0, index 23 and index 28 are all the same value (9). They're all shoes. Let's take a look at the result of running the convolution on each, and you'll begin to see common features between them emerge. Now, when the DNN is training on that data, it's working with a lot less, and it's perhaps finding a commonality between shoes based on this convolution/pooling combination."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f-6nX4QsOku6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "01641d23-9385-4495-9cac-683d2815a386"
      },
      "source": [
        "print(test_labels[:100])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9FGsHhv6JvDx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "4f7642e8-22e8-4710-ab73-670919d40887"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, axarr = plt.subplots(3,4)\n",
        "FIRST_IMAGE=0\n",
        "SECOND_IMAGE=7\n",
        "THIRD_IMAGE=26\n",
        "CONVOLUTION_NUMBER = 1\n",
        "from tensorflow.keras import models\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
        "for x in range(0,4):\n",
        "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[0,x].grid(False)\n",
        "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[1,x].grid(False)\n",
        "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[2,x].grid(False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8KVPZqgHo5Ux"
      },
      "source": [
        "EXERCISES\n",
        "\n",
        "1. Try editing the convolutions. Change the 32s to either 16 or 64. What impact will this have on accuracy and/or training time.\n",
        "\n",
        "2. Remove the final Convolution. What impact will this have on accuracy or training time?\n",
        "\n",
        "3. How about adding more Convolutions? What impact do you think this will have? Experiment with it.\n",
        "\n",
        "4. Remove all Convolutions but the first. What impact do you think this will have? Experiment with it. \n",
        "\n",
        "5. In the previous lesson you implemented a callback to check on the loss function and to cancel training once it hit a certain amount. See if you can implement that here!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZpYRidBXpBPM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e8767e66-4997-4443-9239-5195be3693ae"
      },
      "source": [
        "#REGULAR WITH CONVOLUTIONS 32\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1406 - accuracy: 0.9570\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0464 - accuracy: 0.9857\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0327 - accuracy: 0.9898\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0241 - accuracy: 0.9921\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0178 - accuracy: 0.9941\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.9889\n",
            "0.9889000058174133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O4Ca6Tj_W3I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "edab88c4-bb6d-4de5-824b-5988b212e36b"
      },
      "source": [
        "#SINGLE CONVOLUTION 32\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1536 - accuracy: 0.9542\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0533 - accuracy: 0.9831\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0340 - accuracy: 0.9891\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0235 - accuracy: 0.9925\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0167 - accuracy: 0.9945\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0406 - accuracy: 0.9872\n",
            "0.9872000217437744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBSxGgQR_YNr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "af1f1c8a-6c54-4231-bfc8-6044a2af65e5"
      },
      "source": [
        "#REGULAR WITH COVOLUTIONS 64\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1209 - accuracy: 0.9629\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0396 - accuracy: 0.9875\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0270 - accuracy: 0.9914\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0182 - accuracy: 0.9940\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0143 - accuracy: 0.9957\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0341 - accuracy: 0.9905\n",
            "0.9904999732971191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vgxsx5C_v3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "45d637ad-2f13-4d7f-ca83-3c06d2966cb7"
      },
      "source": [
        "#SINGLE COVOLUTION 64\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1442 - accuracy: 0.9559\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0493 - accuracy: 0.9851\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0299 - accuracy: 0.9906\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0200 - accuracy: 0.9935\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0135 - accuracy: 0.9953\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0511 - accuracy: 0.9852\n",
            "0.9851999878883362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_JIUxLMAB8X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7c0724e5-b3c3-4395-e3d3-e71a9dc62231"
      },
      "source": [
        "#MORE CONVOLUTIONS 32\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2464 - accuracy: 0.9231\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0917 - accuracy: 0.9723\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0681 - accuracy: 0.9790\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0555 - accuracy: 0.9829\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0457 - accuracy: 0.9852\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0619 - accuracy: 0.9807\n",
            "0.9807000160217285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E40ZLAJAZ7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e55e1425-fa7c-4139-b655-6fee72ea4bfb"
      },
      "source": [
        "#MORE CONVOLUTIONS 64\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2089 - accuracy: 0.9348\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0720 - accuracy: 0.9777\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0535 - accuracy: 0.9839\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0404 - accuracy: 0.9871\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0333 - accuracy: 0.9894\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9870\n",
            "0.9869999885559082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7zaMJyxAlBi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "92d44072-c13f-483f-aecc-59384704e281"
      },
      "source": [
        "#SINGLE CONVOLUTIONS (W/O FIRST CONVOLUTION)\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  # tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  # tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1421 - accuracy: 0.9574\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0490 - accuracy: 0.9847\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0314 - accuracy: 0.9902\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0193 - accuracy: 0.9937\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0137 - accuracy: 0.9957\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0508 - accuracy: 0.9860\n",
            "0.9860000014305115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBO88Qf0A8mK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0374d3fa-dc30-465c-b297-34a9dd4c33da"
      },
      "source": [
        "#WITH CALLBACK\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "class ImplementedCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if logs.get('accuracy') >= 0.90:\n",
        "      print(\"\\nReached 90% accuracy, so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callback = ImplementedCallback()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=callback)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "Epoch 1/5\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.1264 - accuracy: 0.9614\n",
            "Reached 90% accuracy, so cancelling training!\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1261 - accuracy: 0.9615\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0492 - accuracy: 0.9821\n",
            "0.9821000099182129\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}